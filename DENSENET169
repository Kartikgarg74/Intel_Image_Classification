{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport cv2\nimport zipfile\nimport shutil\nimport random\nimport pandas as pd\nimport csv\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:05.523696Z","iopub.execute_input":"2024-12-08T05:06:05.523945Z","iopub.status.idle":"2024-12-08T05:06:18.851823Z","shell.execute_reply.started":"2024-12-08T05:06:05.523918Z","shell.execute_reply":"2024-12-08T05:06:18.851046Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Paths to training and testing data\ntrain_data_path = '/kaggle/input/intel-image-classification/seg_train/seg_train/'\ntest_data_path = '/kaggle/input/intel-image-classification/seg_test/seg_test/'\n\n# Output directories for models and reports\noutput_dir = '/kaggle/working'\nmodels_dir = os.path.join(output_dir, \"models\")\nreports_dir = os.path.join(output_dir, \"reports\")\nos.makedirs(models_dir, exist_ok=True)\nos.makedirs(reports_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.853887Z","iopub.execute_input":"2024-12-08T05:06:18.854386Z","iopub.status.idle":"2024-12-08T05:06:18.859533Z","shell.execute_reply.started":"2024-12-08T05:06:18.854356Z","shell.execute_reply":"2024-12-08T05:06:18.858663Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.860711Z","iopub.execute_input":"2024-12-08T05:06:18.861082Z","iopub.status.idle":"2024-12-08T05:06:18.889688Z","shell.execute_reply.started":"2024-12-08T05:06:18.861037Z","shell.execute_reply":"2024-12-08T05:06:18.888868Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Set data augmentation techniques\n\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,vertical_flip=True\n                                                             ,zoom_range=0.2,rotation_range=360\n                                                             ,width_shift_range=0.1,height_shift_range=0.1\n                                                             ,channel_shift_range=50\n                                                             ,brightness_range=(0,1.2)\n                                                             ,preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.890686Z","iopub.execute_input":"2024-12-08T05:06:18.890946Z","iopub.status.idle":"2024-12-08T05:06:18.899313Z","shell.execute_reply.started":"2024-12-08T05:06:18.890921Z","shell.execute_reply":"2024-12-08T05:06:18.898729Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Loading images directly from directories\nbatch_size = 70\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\nvalidation_generator = test_datagen.flow_from_directory(\n    test_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.900272Z","iopub.execute_input":"2024-12-08T05:06:18.900594Z","iopub.status.idle":"2024-12-08T05:06:40.598577Z","shell.execute_reply.started":"2024-12-08T05:06:18.900560Z","shell.execute_reply":"2024-12-08T05:06:40.597919Z"}},"outputs":[{"name":"stdout","text":"Found 14034 images belonging to 6 classes.\nFound 3000 images belonging to 6 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## GAP layer","metadata":{}},{"cell_type":"code","source":"import keras\nimport matplotlib.pyplot as plt\nimport csv\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras import backend as K\n\n# Clear backend\nkeras.backend.clear_session()\n\n# Model setup\nshape = (224, 224, 3)\ninput_tensor = keras.Input(shape=shape)\nbase_model = keras.applications.DenseNet169(input_tensor=input_tensor, weights=None, include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\npreds = keras.layers.Dense(\n    6,\n    activation='softmax',\n    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n    bias_initializer=keras.initializers.Zeros()\n)(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=preds)\n\n# Set layers to be trainable\nfor layer in model.layers:\n    layer.trainable = True\n#model.summary()\n\n\n\n\n# Adaptive learning rate\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.045,\n    decay_steps=2 * int(len(train_generator.filenames) / batch_size),\n    decay_rate=0.94,\n    staircase=True\n)\noptimizer = keras.optimizers.SGD(momentum=0.9, learning_rate=lr_schedule)\n\n\nclass MetricsCallback(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data):\n        super().__init__()\n        self.validation_data = validation_data\n        self.precision_list = []\n        self.recall_list = []\n        self.f1_list = []\n        self.sensitivity_list = []\n        self.specificity_list = []\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_images, val_labels = self.validation_data\n\n        y_pred = self.model.predict(val_images)\n        y_true = val_labels\n\n        y_pred_labels = tf.argmax(y_pred, axis=1).numpy()\n        y_true_labels = tf.argmax(y_true, axis=1).numpy()\n\n        # Use sklearn's confusion matrix with multi-class support\n        cm = confusion_matrix(y_true_labels, y_pred_labels)\n        \n        # Calculate metrics for each class and then average\n        precisions = []\n        recalls = []\n        f1_scores = []\n        specificities = []\n\n        for i in range(cm.shape[0]):\n            # Calculate true positive, false positive, true negative, false negative for each class\n            tp = cm[i, i]\n            fn = cm[i, :].sum() - tp\n            fp = cm[:, i].sum() - tp\n            tn = cm.sum() - (tp + fn + fp)\n\n            # Precision\n            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n            \n            # Recall (Sensitivity)\n            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n            \n            # F1 Score\n            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n            \n            # Specificity\n            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n\n            precisions.append(precision)\n            recalls.append(recall)\n            f1_scores.append(f1_score)\n            specificities.append(specificity)\n\n        # Store average metrics\n        self.precision_list.append(np.mean(precisions))\n        self.recall_list.append(np.mean(recalls))\n        self.f1_list.append(np.mean(f1_scores))\n        self.sensitivity_list.append(np.mean(recalls))\n        self.specificity_list.append(np.mean(specificities))\n\n# Metrics callback\nvalidation_data = next(iter(validation_generator))\nmetrics_callback = MetricsCallback(validation_data=(validation_data[0], validation_data[1]))\n\n# Save checkpoints after every 10th epoch\ncheckpoint_filepath = \"/kaggle/working/model-{epoch:02d}-{val_accuracy:.4f}.keras\"\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_accuracy',\n    save_best_only=False,  # Ensure it saves even if it's not the \"best\" model\n    mode='max',\n    save_freq='epoch'  # Save by epoch\n)\n\n# Custom callback for saving checkpoints every 10th epoch\nclass SaveEveryNthEpoch(keras.callbacks.Callback):\n    def __init__(self, save_interval):\n        self.save_interval = save_interval\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_interval == 0:  # Save every nth epoch\n            filepath = f\"/kaggle/working/model-{epoch + 1:02d}-{logs['val_accuracy']:.4f}.keras\"\n            self.model.save(filepath)\n            print(f\"Model checkpoint saved at: {filepath}\")\n\n# Add the custom checkpoint callback\nsave_every_10_epochs = SaveEveryNthEpoch(save_interval=10)\n\n# Update callbacks list\ncallbacks_list = [save_every_10_epochs, metrics_callback]\n# Compile model\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n        keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')\n    ]\n)\n\n# Train model\nhist = model.fit(\n    train_generator,\n    epochs=220,\n    validation_data=validation_generator,\n    shuffle=True,\n    callbacks=callbacks_list\n)\n\n# Plot metrics\ndef plot_metrics(history, metrics_callback, title):\n    plt.figure(figsize=(12, 8))\n    \n    # Accuracy and Loss\n    plt.subplot(2, 1, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid()\n\n    plt.subplot(2, 1, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    \n    plt.show()\n\n    # Precision, Recall, F1, Sensitivity, Specificity\n    metrics = ['precision', 'recall', 'f1', 'sensitivity', 'specificity']\n    for metric in metrics:\n        plt.figure(figsize=(12, 6))\n        plt.plot(getattr(metrics_callback, f\"{metric}_list\"), label=f'Validation {metric.capitalize()}')\n        plt.title(f'{metric.capitalize()}')\n        plt.xlabel('Epochs')\n        plt.ylabel(metric.capitalize())\n        plt.legend()\n        plt.grid()\n        plt.show()\n\nplot_metrics(hist, metrics_callback, 'Metrics Summary')\n\n# Save training history to CSV\nwith open('/kaggle/working/reports.csv', mode='w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    for key in hist.history:\n        data = [key]\n        data.extend(hist.history[key])\n        csv_writer.writerow(data)\n\n# Save the final model\nmodel.save('/kaggle/working/final_model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:40.599877Z","iopub.execute_input":"2024-12-08T05:06:40.600119Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/220\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733634462.021020     149 service.cc:145] XLA service 0x787fe40034b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733634462.021078     149 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733634462.021082     149 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733634586.133484     149 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8s/step ep - accuracy: 0.2886 - loss: 1.9525 - precision: 0.4285 - recall: 0.0853 - top_1_accuracy: 0.2886 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 2s/step - accuracy: 0.2889 - loss: 1.9513 - precision: 0.4291 - recall: 0.0855 - top_1_accuracy: 0.2889 - top_5_accuracy: 0.9148 - val_accuracy: 0.3937 - val_loss: 2.0588 - val_precision: 0.6250 - val_recall: 0.1250 - val_top_1_accuracy: 0.3937 - val_top_5_accuracy: 0.9710\nEpoch 2/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step/step - accuracy: 0.4205 - loss: 1.4306 - precision: 0.6540 - recall: 0.1580 - top_1_accuracy: 0.4205 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 1s/step - accuracy: 0.4205 - loss: 1.4304 - precision: 0.6541 - recall: 0.1581 - top_1_accuracy: 0.4205 - top_5_accuracy: 0.9715 - val_accuracy: 0.3740 - val_loss: 7.3774 - val_precision: 0.3805 - val_recall: 0.2563 - val_top_1_accuracy: 0.3740 - val_top_5_accuracy: 0.9213\nEpoch 3/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/stepep - accuracy: 0.4657 - loss: 1.3053 - precision: 0.6674 - recall: 0.2210 - top_1_accuracy: 0.4657 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 1s/step - accuracy: 0.4657 - loss: 1.3053 - precision: 0.6674 - recall: 0.2211 - top_1_accuracy: 0.4657 - top_5_accuracy: 0.9795 - val_accuracy: 0.4530 - val_loss: 1.6345 - val_precision: 0.6517 - val_recall: 0.1983 - val_top_1_accuracy: 0.4530 - val_top_5_accuracy: 0.9880\nEpoch 4/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step/step - accuracy: 0.4926 - loss: 1.2518 - precision: 0.6738 - recall: 0.2646 - top_1_accuracy: 0.4926 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 1s/step - accuracy: 0.4927 - loss: 1.2517 - precision: 0.6739 - recall: 0.2646 - top_1_accuracy: 0.4927 - top_5_accuracy: 0.9786 - val_accuracy: 0.5530 - val_loss: 1.2499 - val_precision: 0.7074 - val_recall: 0.3320 - val_top_1_accuracy: 0.5530 - val_top_5_accuracy: 0.9903\nEpoch 5/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step/step - accuracy: 0.5146 - loss: 1.2083 - precision: 0.7041 - recall: 0.3099 - top_1_accuracy: 0.5146 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 1s/step - accuracy: 0.5146 - loss: 1.2082 - precision: 0.7041 - recall: 0.3099 - top_1_accuracy: 0.5146 - top_5_accuracy: 0.9836 - val_accuracy: 0.5127 - val_loss: 1.2360 - val_precision: 0.5842 - val_recall: 0.3840 - val_top_1_accuracy: 0.5127 - val_top_5_accuracy: 0.9927\nEpoch 6/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step/step - accuracy: 0.5446 - loss: 1.1606 - precision: 0.6984 - recall: 0.3456 - top_1_accuracy: 0.5446 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 1s/step - accuracy: 0.5446 - loss: 1.1605 - precision: 0.6985 - recall: 0.3457 - top_1_accuracy: 0.5446 - top_5_accuracy: 0.9849 - val_accuracy: 0.5943 - val_loss: 1.2986 - val_precision: 0.7067 - val_recall: 0.4320 - val_top_1_accuracy: 0.5943 - val_top_5_accuracy: 0.9880\nEpoch 7/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step/step - accuracy: 0.5609 - loss: 1.1104 - precision: 0.7158 - recall: 0.3851 - top_1_accuracy: 0.5609 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 1.1103 - precision: 0.7158 - recall: 0.3851 - top_1_accuracy: 0.5610 - top_5_accuracy: 0.9864 - val_accuracy: 0.6267 - val_loss: 0.9720 - val_precision: 0.7297 - val_recall: 0.4887 - val_top_1_accuracy: 0.6267 - val_top_5_accuracy: 0.9920\nEpoch 8/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/stepep - accuracy: 0.5934 - loss: 1.0559 - precision: 0.7307 - recall: 0.4292 - top_1_accuracy: 0.5934 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 1s/step - accuracy: 0.5934 - loss: 1.0559 - precision: 0.7307 - recall: 0.4292 - top_1_accuracy: 0.5934 - top_5_accuracy: 0.9889 - val_accuracy: 0.5627 - val_loss: 1.1856 - val_precision: 0.6517 - val_recall: 0.4560 - val_top_1_accuracy: 0.5627 - val_top_5_accuracy: 0.9897\nEpoch 9/220\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step/step - accuracy: 0.5868 - loss: 1.0474 - precision: 0.7149 - recall: 0.4390 - top_1_accuracy: 0.5868 - top_5_accuracy: 0.9\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 1s/step - accuracy: 0.5868 - loss: 1.0474 - precision: 0.7149 - recall: 0.4391 - top_1_accuracy: 0.5868 - top_5_accuracy: 0.9889 - val_accuracy: 0.5860 - val_loss: 1.9470 - val_precision: 0.6910 - val_recall: 0.4413 - val_top_1_accuracy: 0.5860 - val_top_5_accuracy: 0.9863\nEpoch 10/220\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977ms/step - accuracy: 0.5870 - loss: 1.0564 - precision: 0.7254 - recall: 0.4425 - top_1_accuracy: 0.5870 - top_5_accuracy: 0.9853Model checkpoint saved at: /kaggle/working/model-10-0.6333.keras\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 1s/step - accuracy: 0.5870 - loss: 1.0563 - precision: 0.7254 - recall: 0.4426 - top_1_accuracy: 0.5870 - top_5_accuracy: 0.9853 - val_accuracy: 0.6333 - val_loss: 1.2508 - val_precision: 0.7248 - val_recall: 0.5180 - val_top_1_accuracy: 0.6333 - val_top_5_accuracy: 0.9930\nEpoch 11/220\n\u001b[1m 96/201\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 1s/step - accuracy: 0.6173 - loss: 1.0121 - precision: 0.7353 - recall: 0.4618 - top_1_accuracy: 0.6173 - top_5_accuracy: 0.9907","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n# Evaluate on test data\ntest_data_path = '/kaggle/input/intel-image-classification/seg_test/seg_test/'\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\ntest_results = model.evaluate(test_generator)\nprint(f\"Test Loss: {test_results[0]}\")\nprint(f\"Test Accuracy: {test_results[1]}\")\nprint(f\"Top-1 Accuracy: {test_results[2]}\")\nprint(f\"Top-5 Accuracy: {test_results[3]}\")\n\n# Predict on test data\ny_pred = model.predict(test_generator)\ny_true = test_generator.classes\ny_pred_classes = y_pred.argmax(axis=-1)\n\n# Compute classification report\nprint(classification_report(y_true, y_pred_classes))\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred_classes)\nprint(\"Confusion Matrix:\\n\", cm)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}