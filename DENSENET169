{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport cv2\nimport zipfile\nimport shutil\nimport random\nimport pandas as pd\nimport csv\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:05.523696Z","iopub.execute_input":"2024-12-08T05:06:05.523945Z","iopub.status.idle":"2024-12-08T05:06:18.851823Z","shell.execute_reply.started":"2024-12-08T05:06:05.523918Z","shell.execute_reply":"2024-12-08T05:06:18.851046Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Paths to training and testing data\ntrain_data_path = '/kaggle/input/intel-image-classification/seg_train/seg_train/'\ntest_data_path = '/kaggle/input/intel-image-classification/seg_test/seg_test/'\n\n# Output directories for models and reports\noutput_dir = '/kaggle/working'\nmodels_dir = os.path.join(output_dir, \"models\")\nreports_dir = os.path.join(output_dir, \"reports\")\nos.makedirs(models_dir, exist_ok=True)\nos.makedirs(reports_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.853887Z","iopub.execute_input":"2024-12-08T05:06:18.854386Z","iopub.status.idle":"2024-12-08T05:06:18.859533Z","shell.execute_reply.started":"2024-12-08T05:06:18.854356Z","shell.execute_reply":"2024-12-08T05:06:18.858663Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.860711Z","iopub.execute_input":"2024-12-08T05:06:18.861082Z","iopub.status.idle":"2024-12-08T05:06:18.889688Z","shell.execute_reply.started":"2024-12-08T05:06:18.861037Z","shell.execute_reply":"2024-12-08T05:06:18.888868Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Set data augmentation techniques\n\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,vertical_flip=True\n                                                             ,zoom_range=0.2,rotation_range=360\n                                                             ,width_shift_range=0.1,height_shift_range=0.1\n                                                             ,channel_shift_range=50\n                                                             ,brightness_range=(0,1.2)\n                                                             ,preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.890686Z","iopub.execute_input":"2024-12-08T05:06:18.890946Z","iopub.status.idle":"2024-12-08T05:06:18.899313Z","shell.execute_reply.started":"2024-12-08T05:06:18.890921Z","shell.execute_reply":"2024-12-08T05:06:18.898729Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Loading images directly from directories\nbatch_size = 70\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\nvalidation_generator = test_datagen.flow_from_directory(\n    test_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:18.900272Z","iopub.execute_input":"2024-12-08T05:06:18.900594Z","iopub.status.idle":"2024-12-08T05:06:40.598577Z","shell.execute_reply.started":"2024-12-08T05:06:18.900560Z","shell.execute_reply":"2024-12-08T05:06:40.597919Z"}},"outputs":[{"name":"stdout","text":"Found 14034 images belonging to 6 classes.\nFound 3000 images belonging to 6 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## GAP layer","metadata":{}},{"cell_type":"code","source":"import keras\nimport matplotlib.pyplot as plt\nimport csv\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras import backend as K\n\n# Clear backend\nkeras.backend.clear_session()\n\n# Model setup\nshape = (224, 224, 3)\ninput_tensor = keras.Input(shape=shape)\nbase_model = keras.applications.DenseNet169(input_tensor=input_tensor, weights=None, include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\npreds = keras.layers.Dense(\n    6,\n    activation='softmax',\n    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n    bias_initializer=keras.initializers.Zeros()\n)(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=preds)\n\n# Set layers to be trainable\nfor layer in model.layers:\n    layer.trainable = True\n#model.summary()\n\n\n\n\n# Adaptive learning rate\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.045,\n    decay_steps=2 * int(len(train_generator.filenames) / batch_size),\n    decay_rate=0.94,\n    staircase=True\n)\noptimizer = keras.optimizers.SGD(momentum=0.9, learning_rate=lr_schedule)\n\n\nclass MetricsCallback(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data):\n        super().__init__()\n        self.validation_data = validation_data\n        self.precision_list = []\n        self.recall_list = []\n        self.f1_list = []\n        self.sensitivity_list = []\n        self.specificity_list = []\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_images, val_labels = self.validation_data\n\n        y_pred = self.model.predict(val_images)\n        y_true = val_labels\n\n        y_pred_labels = tf.argmax(y_pred, axis=1).numpy()\n        y_true_labels = tf.argmax(y_true, axis=1).numpy()\n\n        # Use sklearn's confusion matrix with multi-class support\n        cm = confusion_matrix(y_true_labels, y_pred_labels)\n        \n        # Calculate metrics for each class and then average\n        precisions = []\n        recalls = []\n        f1_scores = []\n        specificities = []\n\n        for i in range(cm.shape[0]):\n            # Calculate true positive, false positive, true negative, false negative for each class\n            tp = cm[i, i]\n            fn = cm[i, :].sum() - tp\n            fp = cm[:, i].sum() - tp\n            tn = cm.sum() - (tp + fn + fp)\n\n            # Precision\n            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n            \n            # Recall (Sensitivity)\n            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n            \n            # F1 Score\n            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n            \n            # Specificity\n            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n\n            precisions.append(precision)\n            recalls.append(recall)\n            f1_scores.append(f1_score)\n            specificities.append(specificity)\n\n        # Store average metrics\n        self.precision_list.append(np.mean(precisions))\n        self.recall_list.append(np.mean(recalls))\n        self.f1_list.append(np.mean(f1_scores))\n        self.sensitivity_list.append(np.mean(recalls))\n        self.specificity_list.append(np.mean(specificities))\n\n# Metrics callback\nvalidation_data = next(iter(validation_generator))\nmetrics_callback = MetricsCallback(validation_data=(validation_data[0], validation_data[1]))\n\n# Save checkpoints after every 10th epoch\ncheckpoint_filepath = \"/kaggle/working/model-{epoch:02d}-{val_accuracy:.4f}.keras\"\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_accuracy',\n    save_best_only=False,  # Ensure it saves even if it's not the \"best\" model\n    mode='max',\n    save_freq='epoch'  # Save by epoch\n)\n\n# Custom callback for saving checkpoints every 10th epoch\nclass SaveEveryNthEpoch(keras.callbacks.Callback):\n    def __init__(self, save_interval):\n        self.save_interval = save_interval\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_interval == 0:  # Save every nth epoch\n            filepath = f\"/kaggle/working/model-{epoch + 1:02d}-{logs['val_accuracy']:.4f}.keras\"\n            self.model.save(filepath)\n            print(f\"Model checkpoint saved at: {filepath}\")\n\n# Add the custom checkpoint callback\nsave_every_10_epochs = SaveEveryNthEpoch(save_interval=10)\n\n# Update callbacks list\ncallbacks_list = [save_every_10_epochs, metrics_callback]\n# Compile model\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=[\n        'accuracy',\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n        keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')\n    ]\n)\n\n# Train model\nhist = model.fit(\n    train_generator,\n    epochs=220,\n    validation_data=validation_generator,\n    shuffle=True,\n    callbacks=callbacks_list\n)\n\n# Plot metrics\ndef plot_metrics(history, metrics_callback, title):\n    plt.figure(figsize=(12, 8))\n    \n    # Accuracy and Loss\n    plt.subplot(2, 1, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid()\n\n    plt.subplot(2, 1, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    \n    plt.show()\n\n    # Precision, Recall, F1, Sensitivity, Specificity\n    metrics = ['precision', 'recall', 'f1', 'sensitivity', 'specificity']\n    for metric in metrics:\n        plt.figure(figsize=(12, 6))\n        plt.plot(getattr(metrics_callback, f\"{metric}_list\"), label=f'Validation {metric.capitalize()}')\n        plt.title(f'{metric.capitalize()}')\n        plt.xlabel('Epochs')\n        plt.ylabel(metric.capitalize())\n        plt.legend()\n        plt.grid()\n        plt.show()\n\nplot_metrics(hist, metrics_callback, 'Metrics Summary')\n\n# Save training history to CSV\nwith open('/kaggle/working/reports.csv', mode='w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    for key in hist.history:\n        data = [key]\n        data.extend(hist.history[key])\n        csv_writer.writerow(data)\n\n# Save the final model\nmodel.save('/kaggle/working/final_model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T05:06:40.599877Z","iopub.execute_input":"2024-12-08T05:06:40.600119Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/220\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733634462.021020     149 service.cc:145] XLA service 0x787fe40034b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733634462.021078     149 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733634462.021082     149 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733634586.133484     149 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 12/201\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 1s/step - accuracy: 0.1753 - loss: 2.1228 - precision: 0.1665 - recall: 0.0321 - top_1_accuracy: 0.1753 - top_5_accuracy: 0.8472","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n# Evaluate on test data\ntest_data_path = '/kaggle/input/intel-image-classification/seg_test/seg_test/'\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.imagenet_utils.preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\ntest_results = model.evaluate(test_generator)\nprint(f\"Test Loss: {test_results[0]}\")\nprint(f\"Test Accuracy: {test_results[1]}\")\nprint(f\"Top-1 Accuracy: {test_results[2]}\")\nprint(f\"Top-5 Accuracy: {test_results[3]}\")\n\n# Predict on test data\ny_pred = model.predict(test_generator)\ny_true = test_generator.classes\ny_pred_classes = y_pred.argmax(axis=-1)\n\n# Compute classification report\nprint(classification_report(y_true, y_pred_classes))\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred_classes)\nprint(\"Confusion Matrix:\\n\", cm)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}